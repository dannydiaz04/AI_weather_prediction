{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "weather_data = pd.read_csv(r'D:/CSU/Winter 2021/CSC510 - Foundations of Artificial Intelligence/Portfolio Project/Data/simplemaps_uszips_basicv1.79/climate_data_for_US/combined_climate_data_1980_2021.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''find correlation between variables. Our target variable is tavg\n",
    "    .corr() is the function that will produce a correlation table \n",
    "    then we can plot this out in matplotlib. The dark red means positive strong correlation\n",
    "    and the dark blue mean negative strong correlation. The diagonal line only means the intersection\n",
    "    of an attribute with itself.\n",
    "'''\n",
    "corr = weather_data.corr()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(corr, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0, len(weather_data.columns),1)\n",
    "ax.set_xticks(ticks)\n",
    "plt.xticks(rotation=90)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(weather_data.columns)\n",
    "ax.set_yticklabels(weather_data.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>prcp</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>wpgt</th>\n",
       "      <th>pres</th>\n",
       "      <th>tsun</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-01</th>\n",
       "      <td>-0.4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02</th>\n",
       "      <td>-1.2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-03</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144.3</td>\n",
       "      <td>16.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-04</th>\n",
       "      <td>2.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>296.7</td>\n",
       "      <td>25.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-05</th>\n",
       "      <td>-1.8</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-27</th>\n",
       "      <td>27.5</td>\n",
       "      <td>26.1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.6</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-28</th>\n",
       "      <td>27.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.6</td>\n",
       "      <td>24.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1013.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29</th>\n",
       "      <td>27.8</td>\n",
       "      <td>25.6</td>\n",
       "      <td>30.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>68.8</td>\n",
       "      <td>26.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1013.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-30</th>\n",
       "      <td>27.7</td>\n",
       "      <td>25.6</td>\n",
       "      <td>30.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>72.1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1013.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <td>27.1</td>\n",
       "      <td>23.9</td>\n",
       "      <td>30.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>63.7</td>\n",
       "      <td>18.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1013.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22392724 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tavg  tmin  tmax  prcp   wdir  wspd  wpgt    pres  tsun\n",
       "time                                                               \n",
       "2006-01-01  -0.4  -1.0   0.0   NaN   66.0  17.9   NaN     NaN   NaN\n",
       "2006-01-02  -1.2  -1.0   0.0   NaN    NaN  14.0   NaN     NaN   NaN\n",
       "2006-01-03  -0.1  -1.0   2.0   NaN  144.3  16.3   NaN     NaN   NaN\n",
       "2006-01-04   2.1   1.0   5.0   NaN  296.7  25.1   NaN     NaN   NaN\n",
       "2006-01-05  -1.8  -1.0   1.0   NaN    NaN  17.6   NaN     NaN   NaN\n",
       "...          ...   ...   ...   ...    ...   ...   ...     ...   ...\n",
       "2021-12-27  27.5  26.1  30.0   0.0   59.6  22.0   NaN  1013.0   NaN\n",
       "2021-12-28  27.2  25.0  30.0   0.0   49.6  24.5   NaN  1013.5   NaN\n",
       "2021-12-29  27.8  25.6  30.6   0.3   68.8  26.6   NaN  1013.2   NaN\n",
       "2021-12-30  27.7  25.6  30.6   0.8   72.1  22.0   NaN  1013.6   NaN\n",
       "2021-12-31  27.1  23.9  30.6   0.5   63.7  18.4   NaN  1013.4   NaN\n",
       "\n",
       "[22392724 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''clean and prepare data'''\n",
    "#weather_data\n",
    "\n",
    "''' we need to first only get the columns that are correlated to our target variable (tavg).\n",
    "These variables will be tavg, tmin, tmax, prcp, wdir, wspd,wpgt, pres, tsun'''\n",
    "\n",
    "weather_data_num_variables = weather_data[['tavg', 'tmin', 'tmax', 'prcp', 'wdir', 'wspd', 'wpgt', 'pres', 'tsun']]\n",
    "weather_data_num_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3659209"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''next we'll need to replace all NaN values with the average value in that column. There are several methods I might\n",
    "try here but this is the first and we'll evaluate the result. Another idea I want to try is to omit all rows that \n",
    "have NaN values and use that dataset to predict then use those values to replace NaN values in the original dataset'''\n",
    "\n",
    "# find where there are nulls\n",
    "weather_data_num_variables.tavg.isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danny\\AppData\\Local\\Temp/ipykernel_23324/943630123.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_data_num_variables[column] = weather_data_num_variables[column].fillna(round(weather_data_num_variables[column].mean(), 2))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tavg    0\n",
       "tmin    0\n",
       "tmax    0\n",
       "prcp    0\n",
       "wdir    0\n",
       "wspd    0\n",
       "wpgt    0\n",
       "pres    0\n",
       "tsun    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the mean for each column and replace the NaN's using the fillna() method\n",
    "# then check the results using the isna() and sum() methods\n",
    "\n",
    "for column in weather_data_num_variables.columns:\n",
    "    weather_data_num_variables[column] = weather_data_num_variables[column].fillna(round(weather_data_num_variables[column].mean(), 2))\n",
    "\n",
    "weather_data_num_variables.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tavg</th>\n",
       "      <td>22392724.0</td>\n",
       "      <td>13.422551</td>\n",
       "      <td>9.755067</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>13.42</td>\n",
       "      <td>20.90</td>\n",
       "      <td>48.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmin</th>\n",
       "      <td>22392724.0</td>\n",
       "      <td>9.065861</td>\n",
       "      <td>9.579630</td>\n",
       "      <td>-61.1</td>\n",
       "      <td>1.10</td>\n",
       "      <td>10.00</td>\n",
       "      <td>16.10</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmax</th>\n",
       "      <td>22392724.0</td>\n",
       "      <td>17.648910</td>\n",
       "      <td>11.366932</td>\n",
       "      <td>-97.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>17.65</td>\n",
       "      <td>27.20</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prcp</th>\n",
       "      <td>22392724.0</td>\n",
       "      <td>2.537287</td>\n",
       "      <td>7.297453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.54</td>\n",
       "      <td>4790.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdir</th>\n",
       "      <td>22392724.0</td>\n",
       "      <td>190.899577</td>\n",
       "      <td>60.326792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>190.90</td>\n",
       "      <td>190.90</td>\n",
       "      <td>190.90</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wspd</th>\n",
       "      <td>22392724.0</td>\n",
       "      <td>12.362140</td>\n",
       "      <td>5.844798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.60</td>\n",
       "      <td>12.36</td>\n",
       "      <td>14.90</td>\n",
       "      <td>160.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wpgt</th>\n",
       "      <td>22392724.0</td>\n",
       "      <td>37.600377</td>\n",
       "      <td>6.230176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.60</td>\n",
       "      <td>37.60</td>\n",
       "      <td>37.60</td>\n",
       "      <td>475.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pres</th>\n",
       "      <td>22392724.0</td>\n",
       "      <td>1016.717636</td>\n",
       "      <td>5.681073</td>\n",
       "      <td>905.7</td>\n",
       "      <td>1014.70</td>\n",
       "      <td>1016.72</td>\n",
       "      <td>1018.50</td>\n",
       "      <td>1065.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tsun</th>\n",
       "      <td>22392724.0</td>\n",
       "      <td>376.760661</td>\n",
       "      <td>129.557027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>376.76</td>\n",
       "      <td>376.76</td>\n",
       "      <td>376.76</td>\n",
       "      <td>1422.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count         mean         std    min      25%      50%      75%  \\\n",
       "tavg  22392724.0    13.422551    9.755067  -59.0     7.50    13.42    20.90   \n",
       "tmin  22392724.0     9.065861    9.579630  -61.1     1.10    10.00    16.10   \n",
       "tmax  22392724.0    17.648910   11.366932  -97.0     9.00    17.65    27.20   \n",
       "prcp  22392724.0     2.537287    7.297453    0.0     0.00     0.30     2.54   \n",
       "wdir  22392724.0   190.899577   60.326792    0.0   190.90   190.90   190.90   \n",
       "wspd  22392724.0    12.362140    5.844798    0.0     8.60    12.36    14.90   \n",
       "wpgt  22392724.0    37.600377    6.230176    0.0    37.60    37.60    37.60   \n",
       "pres  22392724.0  1016.717636    5.681073  905.7  1014.70  1016.72  1018.50   \n",
       "tsun  22392724.0   376.760661  129.557027    0.0   376.76   376.76   376.76   \n",
       "\n",
       "         max  \n",
       "tavg    48.8  \n",
       "tmin    47.0  \n",
       "tmax    94.0  \n",
       "prcp  4790.4  \n",
       "wdir   360.0  \n",
       "wspd   160.9  \n",
       "wpgt   475.2  \n",
       "pres  1065.3  \n",
       "tsun  1422.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for outliers\n",
    "weather_data_num_variables.describe().transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danny\\AppData\\Local\\Temp/ipykernel_23324/925395456.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_data_num_variables['Wdirx'] = wv*np.cos(wd_rad)\n",
      "C:\\Users\\danny\\AppData\\Local\\Temp/ipykernel_23324/925395456.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_data_num_variables['Wdiry'] = wv*np.sin(wd_rad)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    the wind speed column is in degrees. For models to make use of the wspd columns, we'll need to convert it to a vector \n",
    "'''\n",
    "\n",
    "wv = weather_data_num_variables.pop('wspd')\n",
    "\n",
    "# Convert to radians.\n",
    "wd_rad = weather_data_num_variables.pop('wdir')*np.pi / 180\n",
    "\n",
    "# Calculate the wind x and y components.\n",
    "weather_data_num_variables['Wdirx'] = wv*np.cos(wd_rad)\n",
    "weather_data_num_variables['Wdiry'] = wv*np.sin(wd_rad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>prcp</th>\n",
       "      <th>wpgt</th>\n",
       "      <th>pres</th>\n",
       "      <th>tsun</th>\n",
       "      <th>Wdirx</th>\n",
       "      <th>Wdiry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-01</th>\n",
       "      <td>-0.4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.54</td>\n",
       "      <td>37.6</td>\n",
       "      <td>1016.72</td>\n",
       "      <td>376.76</td>\n",
       "      <td>7.280586</td>\n",
       "      <td>16.352464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02</th>\n",
       "      <td>-1.2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.54</td>\n",
       "      <td>37.6</td>\n",
       "      <td>1016.72</td>\n",
       "      <td>376.76</td>\n",
       "      <td>-13.747422</td>\n",
       "      <td>-2.647336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-03</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.54</td>\n",
       "      <td>37.6</td>\n",
       "      <td>1016.72</td>\n",
       "      <td>376.76</td>\n",
       "      <td>-13.236961</td>\n",
       "      <td>9.511722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-04</th>\n",
       "      <td>2.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.54</td>\n",
       "      <td>37.6</td>\n",
       "      <td>1016.72</td>\n",
       "      <td>376.76</td>\n",
       "      <td>11.277907</td>\n",
       "      <td>-22.423622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-05</th>\n",
       "      <td>-1.8</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.54</td>\n",
       "      <td>37.6</td>\n",
       "      <td>1016.72</td>\n",
       "      <td>376.76</td>\n",
       "      <td>-17.282473</td>\n",
       "      <td>-3.328080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-27</th>\n",
       "      <td>27.5</td>\n",
       "      <td>26.1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.6</td>\n",
       "      <td>1013.00</td>\n",
       "      <td>376.76</td>\n",
       "      <td>11.132743</td>\n",
       "      <td>18.975301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-28</th>\n",
       "      <td>27.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.6</td>\n",
       "      <td>1013.50</td>\n",
       "      <td>376.76</td>\n",
       "      <td>15.878938</td>\n",
       "      <td>18.657689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29</th>\n",
       "      <td>27.8</td>\n",
       "      <td>25.6</td>\n",
       "      <td>30.6</td>\n",
       "      <td>0.30</td>\n",
       "      <td>37.6</td>\n",
       "      <td>1013.20</td>\n",
       "      <td>376.76</td>\n",
       "      <td>9.619214</td>\n",
       "      <td>24.799813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-30</th>\n",
       "      <td>27.7</td>\n",
       "      <td>25.6</td>\n",
       "      <td>30.6</td>\n",
       "      <td>0.80</td>\n",
       "      <td>37.6</td>\n",
       "      <td>1013.60</td>\n",
       "      <td>376.76</td>\n",
       "      <td>6.761846</td>\n",
       "      <td>20.935077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <td>27.1</td>\n",
       "      <td>23.9</td>\n",
       "      <td>30.6</td>\n",
       "      <td>0.50</td>\n",
       "      <td>37.6</td>\n",
       "      <td>1013.40</td>\n",
       "      <td>376.76</td>\n",
       "      <td>8.152510</td>\n",
       "      <td>16.495350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22392724 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tavg  tmin  tmax  prcp  wpgt     pres    tsun      Wdirx  \\\n",
       "time                                                                   \n",
       "2006-01-01  -0.4  -1.0   0.0  2.54  37.6  1016.72  376.76   7.280586   \n",
       "2006-01-02  -1.2  -1.0   0.0  2.54  37.6  1016.72  376.76 -13.747422   \n",
       "2006-01-03  -0.1  -1.0   2.0  2.54  37.6  1016.72  376.76 -13.236961   \n",
       "2006-01-04   2.1   1.0   5.0  2.54  37.6  1016.72  376.76  11.277907   \n",
       "2006-01-05  -1.8  -1.0   1.0  2.54  37.6  1016.72  376.76 -17.282473   \n",
       "...          ...   ...   ...   ...   ...      ...     ...        ...   \n",
       "2021-12-27  27.5  26.1  30.0  0.00  37.6  1013.00  376.76  11.132743   \n",
       "2021-12-28  27.2  25.0  30.0  0.00  37.6  1013.50  376.76  15.878938   \n",
       "2021-12-29  27.8  25.6  30.6  0.30  37.6  1013.20  376.76   9.619214   \n",
       "2021-12-30  27.7  25.6  30.6  0.80  37.6  1013.60  376.76   6.761846   \n",
       "2021-12-31  27.1  23.9  30.6  0.50  37.6  1013.40  376.76   8.152510   \n",
       "\n",
       "                Wdiry  \n",
       "time                   \n",
       "2006-01-01  16.352464  \n",
       "2006-01-02  -2.647336  \n",
       "2006-01-03   9.511722  \n",
       "2006-01-04 -22.423622  \n",
       "2006-01-05  -3.328080  \n",
       "...               ...  \n",
       "2021-12-27  18.975301  \n",
       "2021-12-28  18.657689  \n",
       "2021-12-29  24.799813  \n",
       "2021-12-30  20.935077  \n",
       "2021-12-31  16.495350  \n",
       "\n",
       "[22392724 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data_num_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Now we can split data. Then we'll want to normalize it. We're going to use a pretty \n",
    "standard set split which is 70% train, 20% validate, 10% test'''\n",
    "\n",
    "column_indices = {name: i for i, name in enumerate(weather_data_num_variables.columns)}\n",
    "\n",
    "n = len(weather_data_num_variables)\n",
    "train_df = weather_data_num_variables[0:int(n*0.7)]\n",
    "val_df = weather_data_num_variables[int(n*0.7):int(n*0.9)]\n",
    "test_df = weather_data_num_variables[int(n*0.9):]\n",
    "\n",
    "num_features = weather_data_num_variables.shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' for the test set we will scale the data. I'll be using Normalization to do this.\n",
    "    Basically, normalization meaning take a value and subtract the mean and divide by the standard deviation. '''\n",
    "    \n",
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "train_df = (train_df - train_mean) / train_std\n",
    "val_df = (val_df - train_mean) / train_std\n",
    "test_df = (test_df - train_mean) / train_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Windowing. Create a class for windows. Tensorflow documentation and other documentation is very helpful making sense of windowing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need to create windows that take input and label data. If we'r predicting a day in the future, we can used windows to use 5 days worth of data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We will make use of creating a class WindowGenerator that will take in labels and width for the train, \n",
    "validate and test sets. This makes our sets reusable and is good practice when working with Deep Learning models\n",
    "such as RNN\n",
    "'''\n",
    "\n",
    "class WindowGenerator():\n",
    "  def __init__(self, input_width, label_width, shift,\n",
    "               train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "               label_columns=None):\n",
    "    # Store the raw data.\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    # Work out the label column indices.\n",
    "    self.label_columns = label_columns\n",
    "    if label_columns is not None:\n",
    "      self.label_columns_indices = {name: i for i, name in\n",
    "                                    enumerate(label_columns)}\n",
    "    self.column_indices = {name: i for i, name in\n",
    "                           enumerate(train_df.columns)}\n",
    "\n",
    "    # Work out the window parameters.\n",
    "    self.input_width = input_width\n",
    "    self.label_width = label_width\n",
    "    self.shift = shift\n",
    "\n",
    "    self.total_window_size = input_width + shift\n",
    "\n",
    "    self.input_slice = slice(0, input_width)\n",
    "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "    self.label_start = self.total_window_size - self.label_width\n",
    "    self.labels_slice = slice(self.label_start, None)\n",
    "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "  def __repr__(self):\n",
    "    return '\\n'.join([\n",
    "        f'Total window size: {self.total_window_size}',\n",
    "        f'Input indices: {self.input_indices}',\n",
    "        f'Label indices: {self.label_indices}',\n",
    "        f'Label column name(s): {self.label_columns}'])\n",
    "\n",
    "  '''The split_window function will split our data into inputs and labels'''\n",
    "  def split_window(self, features):\n",
    "    inputs = features[:, self.input_slice]\n",
    "    labels = features[:, self.labels_slice]\n",
    "    if self.label_columns is not None:\n",
    "        labels = tf.stack(\n",
    "            [labels[:, self.column_indices[name]] for name in self.label_columns], \n",
    "            axis = -1\n",
    "            )\n",
    "\n",
    "    # # set the shape manually since slicing doesn't save the shape\n",
    "    # inputs.set_shape([None, self.input_width, None])\n",
    "    # labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "    return inputs, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total window size: 51\n",
       "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
       " 48 49]\n",
       "Label indices: [50]\n",
       "Label column name(s): ['tavg']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The below instance creates a learning input of 50 days to predict the average temperature (tavg)\n",
    " of one day. The label_width represents that a label is 1 day. We can (and will) add more columns to the\n",
    " label_colums argument\n",
    "'''\n",
    "w1 = WindowGenerator(input_width=50,label_width=1,shift=1, label_columns=['tavg'])\n",
    "\n",
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time\n",
       "2006-01-01   -1.389186\n",
       "2006-01-02   -1.472005\n",
       "2006-01-03   -1.358129\n",
       "2006-01-04   -1.130376\n",
       "2006-01-05   -1.534119\n",
       "                ...   \n",
       "2016-02-08    0.111910\n",
       "2016-02-09    0.422482\n",
       "2016-02-10    0.194729\n",
       "2016-02-11    0.122262\n",
       "2016-02-12    0.453539\n",
       "Name: tavg, Length: 15674906, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['tavg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total window size: 7\n",
       "Input indices: [0 1 2 3 4 5]\n",
       "Label indices: [6]\n",
       "Label column name(s): ['tavg']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2 = WindowGenerator(input_width=6, label_width=1, shift=1,\n",
    "                     label_columns=['tavg'])\n",
    "w2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All shapes are: (batch, time, features)\n",
      "Window shape: (3, 7, 9)\n",
      "Inputs shape: (3, 6, 9)\n",
      "Labels shape: (3, 9, 1)\n"
     ]
    }
   ],
   "source": [
    "# Stack three slices, the length of the total window.\n",
    "example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n",
    "                           np.array(train_df[100:100+w2.total_window_size]),\n",
    "                           np.array(train_df[200:200+w2.total_window_size])])\n",
    "\n",
    "example_inputs, example_labels = w2.split_window(example_window)\n",
    "\n",
    "print('All shapes are: (batch, time, features)')\n",
    "print(f'Window shape: {example_window.shape}')\n",
    "print(f'Inputs shape: {example_inputs.shape}')\n",
    "print(f'Labels shape: {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tf.data.Datasets for standard reuse of datasets in different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(self, data):\n",
    "  data = np.array(data, dtype=np.float32)\n",
    "  ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=self.total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=True,\n",
    "      batch_size=32,)\n",
    "\n",
    "  ds = ds.map(self.split_window)\n",
    "\n",
    "  return ds\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attributes within window generator to access the train, validate, and test datasets  \n",
    "\n",
    "@property\n",
    "def train(self):\n",
    "  return self.make_dataset(self.train_df)\n",
    "\n",
    "@property\n",
    "def val(self):\n",
    "  return self.make_dataset(self.val_df)\n",
    "\n",
    "@property\n",
    "def test(self):\n",
    "  return self.make_dataset(self.test_df)\n",
    "\n",
    "@property\n",
    "def example(self):\n",
    "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "  result = getattr(self, '_example', None)\n",
    "  if result is None:\n",
    "    # No example batch was found, so get one from the `.train` dataset\n",
    "    result = next(iter(self.train))\n",
    "    # And cache it for next time\n",
    "    self._example = result\n",
    "  return result\n",
    "\n",
    "WindowGenerator.train = train\n",
    "WindowGenerator.val = val\n",
    "WindowGenerator.test = test\n",
    "WindowGenerator.example = example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will be using a LSTM recurrent neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next we need to prepare data for an ANN to take it in and do its magic. \n",
    "\n",
    "\n",
    "'''Create the model using tf.keras.Sequential. This model will have two layers using the\n",
    "relu activation function. This is a bit overkill but is used to demostrate how this could be \n",
    "done on another dataset such as one that tensorflow provides called fashion-mnist.'''\n",
    "\n",
    "input_size = 2\n",
    "hidden_layer_size = 2\n",
    "output_size = 1\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(output_size,\n",
    "                            kernel_initializer=tf.random_uniform_initializer(minval=-0.1,maxval=0.1),\n",
    "                            bias_initializer=tf.random_uniform_initializer(minval=-0.1,maxval=0.1)\n",
    "                        )\n",
    "])\n",
    "\n",
    "'''Create a custom optimizer that takes advantage of tensorflow's\n",
    "    pre built optimizers. Here we're using Stochastic Gradient Descent.'''\n",
    "\n",
    "custom_optimizer = tf.keras.optimizers.SGD(learning_rate=0.02)\n",
    "\n",
    "'''Outline the model. Since this is a regression problem and NOT a classification problem, we\n",
    "will only consider looking at the loss.'''\n",
    "\n",
    "model.compile(optimizer=custom_optimizer, loss='mean_squared_error')\n",
    "\n",
    "'''fit the model and run'''\n",
    "\n",
    "model.fit(inputs, targets, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Extract the Weights and Bias'''\n",
    "print('Get the weights and bias')\n",
    "model.layers[0].get_weights()\n",
    "\n",
    "\n",
    "print('Weights')\n",
    "weights = model.layers[0].get_weights()[0]\n",
    "weights\n",
    "\n",
    "\n",
    "print('Bias')\n",
    "bias = model.layers[0].get_weights()[1]\n",
    "bias\n",
    "\n",
    "\n",
    "'''********************PREDICTION********************'''\n",
    "\n",
    "print('''********************PREDICTION********************''')\n",
    "print('Inputs')\n",
    "model.predict_on_batch(inputs).round(1)\n",
    "\n",
    "\n",
    "print('''********************PREDICTION********************''')\n",
    "print('Targets')\n",
    "targets.round(1)\n",
    "\n",
    "\n",
    "test_loss = model.evaluate(inputs, targets)\n",
    "\n",
    "print('\\n\\nFinal Model Loss')\n",
    "print('\\nTest loss: {0:.2f}.'.format(test_loss, test_accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12495dda3933ae8b8e0c3c7ecc6a6e55023f0ed2c2b9c3ebcdd227d4de01f6a0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
